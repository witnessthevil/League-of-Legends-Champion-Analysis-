[2022-12-22T12:55:32.371+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Can_I_change_name_to_this.scrape_counter scheduled__2022-12-21T10:00:00+00:00 [queued]>
[2022-12-22T12:55:32.990+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Can_I_change_name_to_this.scrape_counter scheduled__2022-12-21T10:00:00+00:00 [queued]>
[2022-12-22T12:55:33.037+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2022-12-22T12:55:33.053+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 1
[2022-12-22T12:55:33.063+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2022-12-22T12:55:33.689+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): scrape_counter> on 2022-12-21 10:00:00+00:00
[2022-12-22T12:55:34.249+0000] {standard_task_runner.py:55} INFO - Started process 137 to run task
[2022-12-22T12:55:34.460+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Can_I_change_name_to_this', 'scrape_counter', 'scheduled__2022-12-21T10:00:00+00:00', '--job-id', '202', '--raw', '--subdir', 'DAGS_FOLDER/dags.py', '--cfg-path', '/tmp/tmpw895e1gm']
[2022-12-22T12:55:34.479+0000] {standard_task_runner.py:83} INFO - Job 202: Subtask scrape_counter
[2022-12-22T12:55:38.470+0000] {task_command.py:389} INFO - Running <TaskInstance: Can_I_change_name_to_this.scrape_counter scheduled__2022-12-21T10:00:00+00:00 [running]> on host 502390ac5559
[2022-12-22T12:55:42.141+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=Can_I_change_name_to_this
AIRFLOW_CTX_TASK_ID=scrape_counter
AIRFLOW_CTX_EXECUTION_DATE=2022-12-21T10:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-12-21T10:00:00+00:00
[2022-12-22T12:55:42.227+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2022-12-22T12:55:42.243+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /opt/***/tasks/lol_champ_counter_stat.py ']
[2022-12-22T12:55:42.342+0000] {subprocess.py:86} INFO - Output:
[2022-12-22T12:56:08.594+0000] {subprocess.py:93} INFO - {"message": "now scraping the champ counter stat", "time": "2022-12-22T12:56:08.458175"}
[2022-12-22T12:56:09.127+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:08 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapybot)
[2022-12-22T12:56:09.133+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:08 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.7.15 (default, Nov 15 2022, 10:39:17) - [GCC 10.2.1 20210110], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.10.124-linuxkit-aarch64-with-debian-11.5
[2022-12-22T12:56:09.143+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:08 [scrapy.crawler] INFO: Overridden settings:
[2022-12-22T12:56:09.152+0000] {subprocess.py:93} INFO - {}
[2022-12-22T12:56:09.161+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:08 [py.warnings] WARNING: /home/***/.local/lib/python3.7/site-packages/scrapy/utils/request.py:231: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.
[2022-12-22T12:56:09.172+0000] {subprocess.py:93} INFO - 
[2022-12-22T12:56:09.177+0000] {subprocess.py:93} INFO - It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.
[2022-12-22T12:56:09.193+0000] {subprocess.py:93} INFO - 
[2022-12-22T12:56:09.200+0000] {subprocess.py:93} INFO - See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
[2022-12-22T12:56:09.208+0000] {subprocess.py:93} INFO -   return cls(crawler)
[2022-12-22T12:56:09.210+0000] {subprocess.py:93} INFO - 
[2022-12-22T12:56:09.259+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
[2022-12-22T12:56:09.264+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: 8c4b1dff643d182e
[2022-12-22T12:56:09.685+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:09 [scrapy.middleware] INFO: Enabled extensions:
[2022-12-22T12:56:09.688+0000] {subprocess.py:93} INFO - ['scrapy.extensions.corestats.CoreStats',
[2022-12-22T12:56:09.692+0000] {subprocess.py:93} INFO -  'scrapy.extensions.telnet.TelnetConsole',
[2022-12-22T12:56:09.693+0000] {subprocess.py:93} INFO -  'scrapy.extensions.memusage.MemoryUsage',
[2022-12-22T12:56:09.695+0000] {subprocess.py:93} INFO -  'scrapy.extensions.logstats.LogStats']
[2022-12-22T12:56:14.019+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
[2022-12-22T12:56:14.271+0000] {subprocess.py:93} INFO - ['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
[2022-12-22T12:56:14.277+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
[2022-12-22T12:56:14.280+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
[2022-12-22T12:56:14.289+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
[2022-12-22T12:56:14.293+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.retry.RetryMiddleware',
[2022-12-22T12:56:14.294+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
[2022-12-22T12:56:14.297+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
[2022-12-22T12:56:14.302+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
[2022-12-22T12:56:14.328+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
[2022-12-22T12:56:14.354+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
[2022-12-22T12:56:14.368+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.stats.DownloaderStats']
[2022-12-22T12:56:14.529+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:14 [scrapy.middleware] INFO: Enabled spider middlewares:
[2022-12-22T12:56:14.544+0000] {subprocess.py:93} INFO - ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
[2022-12-22T12:56:14.552+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
[2022-12-22T12:56:14.554+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.referer.RefererMiddleware',
[2022-12-22T12:56:14.562+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
[2022-12-22T12:56:14.570+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.depth.DepthMiddleware']
[2022-12-22T12:56:14.579+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:14 [scrapy.middleware] INFO: Enabled item pipelines:
[2022-12-22T12:56:14.581+0000] {subprocess.py:93} INFO - []
[2022-12-22T12:56:14.604+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:14 [scrapy.core.engine] INFO: Spider opened
[2022-12-22T12:56:37.103+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[2022-12-22T12:56:39.947+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[2022-12-22T12:56:56.986+0000] {subprocess.py:93} INFO - 2022-12-22 12:56:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.metasrc.com/5v5/stats> (referer: None)
[2022-12-22T12:57:00.125+0000] {subprocess.py:93} INFO - 2022-12-22 12:57:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.metasrc.com/5v5/champion/aatrox/top> (referer: https://www.metasrc.com/5v5/stats)
[2022-12-22T12:57:15.148+0000] {subprocess.py:93} INFO - 2022-12-22 12:57:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/ahri/mid> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T12:57:15.505+0000] {subprocess.py:93} INFO - 2022-12-22 12:57:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/akali/top> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T12:57:18.974+0000] {subprocess.py:93} INFO - 2022-12-22 12:57:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/akali/mid> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T12:57:23.427+0000] {subprocess.py:93} INFO - 2022-12-22 12:57:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.metasrc.com/5v5/champion/anivia/mid> (referer: https://www.metasrc.com/5v5/stats)
[2022-12-22T12:57:30.789+0000] {subprocess.py:93} INFO - 2022-12-22 12:57:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/akshan/mid> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T12:58:13.881+0000] {subprocess.py:93} INFO - 2022-12-22 12:58:06 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
[2022-12-22T12:58:32.820+0000] {subprocess.py:93} INFO - 2022-12-22 12:58:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.metasrc.com/5v5/champion/ahri/mid> (referer: https://www.metasrc.com/5v5/stats)
[2022-12-22T12:59:34.555+0000] {subprocess.py:93} INFO - 2022-12-22 12:59:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/amumu/jungle> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T13:01:52.180+0000] {subprocess.py:93} INFO - 2022-12-22 13:01:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/amumu/support> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T13:02:13.834+0000] {subprocess.py:93} INFO - 2022-12-22 13:02:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/alistar/support> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T13:02:46.306+0000] {subprocess.py:93} INFO - 2022-12-22 13:02:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/anivia/support> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
[2022-12-22T13:02:49.789+0000] {subprocess.py:93} INFO - 2022-12-22 13:02:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.metasrc.com/5v5/champion/akali/top> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
