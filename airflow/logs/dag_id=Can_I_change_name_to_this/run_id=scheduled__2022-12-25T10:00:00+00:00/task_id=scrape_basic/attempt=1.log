[2022-12-26T10:01:23.932+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Can_I_change_name_to_this.scrape_basic scheduled__2022-12-25T10:00:00+00:00 [queued]>
[2022-12-26T10:01:23.974+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Can_I_change_name_to_this.scrape_basic scheduled__2022-12-25T10:00:00+00:00 [queued]>
[2022-12-26T10:01:23.984+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2022-12-26T10:01:23.992+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 1
[2022-12-26T10:01:23.994+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2022-12-26T10:01:24.075+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): scrape_basic> on 2022-12-25 10:00:00+00:00
[2022-12-26T10:01:24.124+0000] {standard_task_runner.py:55} INFO - Started process 112 to run task
[2022-12-26T10:01:24.133+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Can_I_change_name_to_this', 'scrape_basic', 'scheduled__2022-12-25T10:00:00+00:00', '--job-id', '265', '--raw', '--subdir', 'DAGS_FOLDER/dags.py', '--cfg-path', '/tmp/tmpj2prc92_']
[2022-12-26T10:01:24.136+0000] {standard_task_runner.py:83} INFO - Job 265: Subtask scrape_basic
[2022-12-26T10:01:24.257+0000] {task_command.py:389} INFO - Running <TaskInstance: Can_I_change_name_to_this.scrape_basic scheduled__2022-12-25T10:00:00+00:00 [running]> on host 502390ac5559
[2022-12-26T10:01:24.392+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=Can_I_change_name_to_this
AIRFLOW_CTX_TASK_ID=scrape_basic
AIRFLOW_CTX_EXECUTION_DATE=2022-12-25T10:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-12-25T10:00:00+00:00
[2022-12-26T10:01:24.401+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2022-12-26T10:01:24.411+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /opt/***/tasks/lol_champ_basic_stat.py ']
[2022-12-26T10:01:24.447+0000] {subprocess.py:86} INFO - Output:
[2022-12-26T10:01:26.528+0000] {subprocess.py:93} INFO - {"message": "now scraping the champ basic stat", "time": "2022-12-26T10:01:26.517422"}
[2022-12-26T10:01:26.570+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapybot)
[2022-12-26T10:01:26.572+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.7.15 (default, Nov 15 2022, 10:39:17) - [GCC 10.2.1 20210110], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.10.124-linuxkit-aarch64-with-debian-11.5
[2022-12-26T10:01:26.574+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.crawler] INFO: Overridden settings:
[2022-12-26T10:01:26.577+0000] {subprocess.py:93} INFO - {}
[2022-12-26T10:01:26.579+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [py.warnings] WARNING: /home/***/.local/lib/python3.7/site-packages/scrapy/utils/request.py:231: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.
[2022-12-26T10:01:26.583+0000] {subprocess.py:93} INFO - 
[2022-12-26T10:01:26.585+0000] {subprocess.py:93} INFO - It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.
[2022-12-26T10:01:26.588+0000] {subprocess.py:93} INFO - 
[2022-12-26T10:01:26.590+0000] {subprocess.py:93} INFO - See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
[2022-12-26T10:01:26.592+0000] {subprocess.py:93} INFO -   return cls(crawler)
[2022-12-26T10:01:26.593+0000] {subprocess.py:93} INFO - 
[2022-12-26T10:01:26.598+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
[2022-12-26T10:01:26.600+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.extensions.telnet] INFO: Telnet Password: 7fabb691569db1ec
[2022-12-26T10:01:26.627+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.middleware] INFO: Enabled extensions:
[2022-12-26T10:01:26.629+0000] {subprocess.py:93} INFO - ['scrapy.extensions.corestats.CoreStats',
[2022-12-26T10:01:26.630+0000] {subprocess.py:93} INFO -  'scrapy.extensions.telnet.TelnetConsole',
[2022-12-26T10:01:26.631+0000] {subprocess.py:93} INFO -  'scrapy.extensions.memusage.MemoryUsage',
[2022-12-26T10:01:26.632+0000] {subprocess.py:93} INFO -  'scrapy.extensions.logstats.LogStats']
[2022-12-26T10:01:26.777+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
[2022-12-26T10:01:26.780+0000] {subprocess.py:93} INFO - ['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
[2022-12-26T10:01:26.782+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
[2022-12-26T10:01:26.783+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
[2022-12-26T10:01:26.785+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
[2022-12-26T10:01:26.786+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.retry.RetryMiddleware',
[2022-12-26T10:01:26.799+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
[2022-12-26T10:01:26.800+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
[2022-12-26T10:01:26.801+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
[2022-12-26T10:01:26.802+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
[2022-12-26T10:01:26.803+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
[2022-12-26T10:01:26.806+0000] {subprocess.py:93} INFO -  'scrapy.downloadermiddlewares.stats.DownloaderStats']
[2022-12-26T10:01:26.807+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.middleware] INFO: Enabled spider middlewares:
[2022-12-26T10:01:26.809+0000] {subprocess.py:93} INFO - ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
[2022-12-26T10:01:26.810+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
[2022-12-26T10:01:26.812+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.referer.RefererMiddleware',
[2022-12-26T10:01:26.814+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
[2022-12-26T10:01:26.815+0000] {subprocess.py:93} INFO -  'scrapy.spidermiddlewares.depth.DepthMiddleware']
[2022-12-26T10:01:26.816+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.middleware] INFO: Enabled item pipelines:
[2022-12-26T10:01:26.817+0000] {subprocess.py:93} INFO - []
[2022-12-26T10:01:26.817+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.core.engine] INFO: Spider opened
[2022-12-26T10:01:26.916+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[2022-12-26T10:01:26.923+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
[2022-12-26T10:01:27.308+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.metasrc.com/5v5/stats> (referer: None)
[2022-12-26T10:01:27.776+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:27 [scrapy.core.engine] INFO: Closing spider (finished)
[2022-12-26T10:01:27.783+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
[2022-12-26T10:01:27.785+0000] {subprocess.py:93} INFO - {'downloader/request_bytes': 310,
[2022-12-26T10:01:27.789+0000] {subprocess.py:93} INFO -  'downloader/request_count': 1,
[2022-12-26T10:01:27.793+0000] {subprocess.py:93} INFO -  'downloader/request_method_count/GET': 1,
[2022-12-26T10:01:27.797+0000] {subprocess.py:93} INFO -  'downloader/response_bytes': 34712,
[2022-12-26T10:01:27.800+0000] {subprocess.py:93} INFO -  'downloader/response_count': 1,
[2022-12-26T10:01:27.802+0000] {subprocess.py:93} INFO -  'downloader/response_status_count/200': 1,
[2022-12-26T10:01:27.804+0000] {subprocess.py:93} INFO -  'elapsed_time_seconds': 0.866384,
[2022-12-26T10:01:27.806+0000] {subprocess.py:93} INFO -  'finish_reason': 'finished',
[2022-12-26T10:01:27.808+0000] {subprocess.py:93} INFO -  'finish_time': datetime.datetime(2022, 12, 26, 10, 1, 27, 783001),
[2022-12-26T10:01:27.814+0000] {subprocess.py:93} INFO -  'httpcompression/response_bytes': 490720,
[2022-12-26T10:01:27.816+0000] {subprocess.py:93} INFO -  'httpcompression/response_count': 1,
[2022-12-26T10:01:27.818+0000] {subprocess.py:93} INFO -  'log_count/DEBUG': 2,
[2022-12-26T10:01:27.819+0000] {subprocess.py:93} INFO -  'log_count/INFO': 10,
[2022-12-26T10:01:27.821+0000] {subprocess.py:93} INFO -  'log_count/WARNING': 1,
[2022-12-26T10:01:27.824+0000] {subprocess.py:93} INFO -  'memusage/max': 239161344,
[2022-12-26T10:01:27.828+0000] {subprocess.py:93} INFO -  'memusage/startup': 239161344,
[2022-12-26T10:01:27.830+0000] {subprocess.py:93} INFO -  'response_received_count': 1,
[2022-12-26T10:01:27.831+0000] {subprocess.py:93} INFO -  'scheduler/dequeued': 1,
[2022-12-26T10:01:27.840+0000] {subprocess.py:93} INFO -  'scheduler/dequeued/memory': 1,
[2022-12-26T10:01:27.847+0000] {subprocess.py:93} INFO -  'scheduler/enqueued': 1,
[2022-12-26T10:01:27.852+0000] {subprocess.py:93} INFO -  'scheduler/enqueued/memory': 1,
[2022-12-26T10:01:27.854+0000] {subprocess.py:93} INFO -  'start_time': datetime.datetime(2022, 12, 26, 10, 1, 26, 916617)}
[2022-12-26T10:01:27.856+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:27 [scrapy.core.engine] INFO: Spider closed (finished)
[2022-12-26T10:01:27.857+0000] {subprocess.py:93} INFO - {"message": "successfully scrape champ basic stat", "time": "2022-12-26T10:01:27.815998"}
[2022-12-26T10:01:27.860+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:27 [__main__] INFO: successfully scrape champ basic stat
[2022-12-26T10:01:27.863+0000] {subprocess.py:93} INFO - {"message": "scrapying champ stat have used 1.3020893340000157s", "time": "2022-12-26T10:01:27.822054"}
[2022-12-26T10:01:27.864+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:27 [__main__] INFO: scrapying champ stat have used 1.3020893340000157s
[2022-12-26T10:01:27.868+0000] {subprocess.py:93} INFO - {"message": "scrapying champ stat have used cpu scpustats(ctx_switches=4684239, interrupts=3546223, soft_interrupts=1193470, syscalls=0)% and disk sdiskusage(total=245107195904, used=239677104128, free=5430091776, percent=97.8)%", "time": "2022-12-26T10:01:27.839876"}
[2022-12-26T10:01:27.875+0000] {subprocess.py:93} INFO - 2022-12-26 10:01:27 [__main__] INFO: scrapying champ stat have used cpu scpustats(ctx_switches=4684239, interrupts=3546223, soft_interrupts=1193470, syscalls=0)% and disk sdiskusage(total=245107195904, used=239677104128, free=5430091776, percent=97.8)%
[2022-12-26T10:01:28.339+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2022-12-26T10:01:28.754+0000] {taskinstance.py:1327} INFO - Marking task as SUCCESS. dag_id=Can_I_change_name_to_this, task_id=scrape_basic, execution_date=20221225T100000, start_date=20221226T100123, end_date=20221226T100128
[2022-12-26T10:01:28.956+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2022-12-26T10:01:29.051+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
